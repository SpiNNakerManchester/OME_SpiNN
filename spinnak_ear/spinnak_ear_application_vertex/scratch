calc n atoms

        # list indices correspond to atom index
        mv_index_list = []

        # each entry is a list of tuples containing mv indices the mv connects
        # to and the data partition name for the edge
        edge_index_list = []

        # each entry is the ID of the parent vertex - used to obtain parent
        # spike IDs
        parent_index_list = []
        ome_indices = []
        ome_index = len(mv_index_list)
        ome_indices.append(ome_index)
        mv_index_list.append('ome')
        parent_index_list.append([])
        edge_index_list.append([])

        for _ in range(self._model.n_channels):
            drnl_index = len(mv_index_list)
            mv_index_list.append('drnl')
            parent_index_list.append([ome_index])
            edge_index_list.append([])

            # Add the data edges (OME->DRNLs) to the ome entry in the edge list
            edge_index_list[ome_index].append(
                (drnl_index, data_partition_dict['ome']))
            fibres = []
            for __ in range(self._model.n_hsr_per_ihc):
                fibres.append(2)
            for ___ in range(self._model.n_msr_per_ihc):
                fibres.append(1)
            for ____ in range(self._model.n_lsr_per_ihc):
                fibres.append(0)

            random.shuffle(fibres)

            for j in range(self._model.n_ihc):
                ihc_index = len(mv_index_list)

                # randomly pick fibre types
                chosen_indices = [
                    fibres.pop() for _ in range(self._model.n_fibres_per_ihcan)]

                mv_index_list.append(
                    'ihc{}{}{}'.format(
                        chosen_indices.count(0), chosen_indices.count(1),
                        chosen_indices.count(2)))

                # drnl data/command
                # add the IHC mv index to the DRNL edge list entries
                edge_index_list[drnl_index].append(
                    (ihc_index, data_partition_dict['drnl']))
                # add the drnl parent index to the ihc
                parent_index_list.append([drnl_index])
                edge_index_list.append([])

        # generate ihc seeds
        n_ihcans = self._model.n_channels * self._model.n_ihc
        random_range = numpy.arange(n_ihcans * 4, dtype=numpy.uint32)
        ihc_seeds = numpy.random.choice(
            random_range, int(n_ihcans * 4), replace=False)

        # now add on the AN Group vertices
        # builds the binary tree aggregator
        n_child_per_group = self._MAX_N_ATOMS_PER_CORE
        n_angs = n_ihcans

        for row_index in range(n_group_tree_rows):
            n_row_angs = int(numpy.ceil(float(n_angs) / n_child_per_group))
            if row_index > 0:
                ang_indices = [
                    i for i, label in enumerate(mv_index_list)
                    if label == "inter_{}".format(row_index-1)]
            else:
                ang_indices = [
                    i for i, label in enumerate(mv_index_list)
                    if "ihc" in label]

            for an in range(n_row_angs):
                if row_index == n_group_tree_rows-1:
                    mv_index_list.append("group_{}".format(row_index))
                else:
                    mv_index_list.append("inter_{}".format(row_index))
                edge_index_list.append([])
                ang_index = len(mv_index_list) - 1

                # find child ihcans
                child_indices = ang_indices[
                    an * n_child_per_group:an * n_child_per_group +
                    n_child_per_group]
                parent_index_list.append(child_indices)
                for i in child_indices:
                    edge_index_list[i].append((ang_index, 'AN'))
            n_angs = n_row_angs

        return (len(mv_index_list), mv_index_list, parent_index_list,
                edge_index_list, ihc_seeds, ome_indices)














        # data per moc recording
        self._data_size_bytes = (
            (self._model.audio_input.size * self._DATA_ELEMENT_TYPE.size) +
            self._DATA_COUNT_TYPE.size)












 def get_resources_used_by_atoms(self, vertex_slice):
        vertex_label = self._mv_index_list[vertex_slice.lo_atom]
        if vertex_label == "ome":
            sdram_resource_bytes = (9*4) + (6*8) + self._data_size_bytes
            drnl_vertices = [i for i in self._mv_index_list if i == self.DRNL]
            sdram_resource_bytes += (
                len(drnl_vertices) * self._KEY_ELEMENT_TYPE.size)

        elif vertex_label == "mack":
            sdram_resource_bytes = 2*4 + 4 * self._KEY_ELEMENT_TYPE.size

        elif vertex_label == self._DRNL:
            sdram_resource_bytes = 14*4
            sdram_resource_bytes += 512 * 12  # key mask tab
            sdram_resource_bytes += 8 * 8
            sdram_resource_bytes += 256  # max n bytes for conn_lut
            if self._is_recording_moc:
                sdram_resource_bytes += self._data_size_bytes

        # elif vertex_label == "ihc":
        elif "ihc" in vertex_label:
            if self._is_recording_spikes:
                sdram_resource_bytes = (
                    15 * 4 + 1 * self._KEY_ELEMENT_TYPE.size +
                    self._model.n_fibres_per_ihcan * numpy.ceil(
                        self._model.audio_input.size / 8.) * 4)
            else:
                sdram_resource_bytes = 15*4 + 1 * self._KEY_ELEMENT_TYPE.size
        else:  # angroup
            child_vertices = (
                [self._mv_list[vertex_index] for vertex_index
                 in self._parent_index_list[vertex_slice.lo_atom]])
            n_child_keys = len(child_vertices)
            sdram_resource_bytes = 5*4 + 12 * n_child_keys

        container = ResourceContainer(
            sdram=ConstantSDRAM(
                sdram_resource_bytes +
                front_end_common_constants.SYSTEM_BYTES_REQUIREMENT + 8),
            dtcm=DTCMResource(0),
            cpu_cycles=CPUCyclesPerTickResource(0))

        return container